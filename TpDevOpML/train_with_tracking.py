"""
RÃ©gression des scores d'examen - Avec MLflow Tracking
Le scientifique organisÃ© qui documente tout ! ğŸ”¬ğŸ“‹
"""
import mlflow
import mlflow.sklearn
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from datetime import datetime
from mlflow.models.signature import infer_signature

print("ğŸ”¬ ExpÃ©rience ML (rÃ©gression) avec MLflow")
print(f"ğŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# 1. Charger les donnÃ©es
df = pd.read_csv("student_habits_performance.csv")
print("ğŸ“ DonnÃ©es chargÃ©es.")

# 2. PrÃ©paration des features
X = df.drop(columns=["exam_score", "student_id"])
y = df["exam_score"]

# Colonnes catÃ©gorielles Ã  encoder
categorical_cols = X.select_dtypes(include="object").columns.tolist()
numerical_cols = X.select_dtypes(exclude="object").columns.tolist()

# 3. Pipeline de prÃ©traitement
preprocessor = ColumnTransformer([
    ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_cols)
], remainder='passthrough')

# 4. Pipeline complet
model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", RandomForestRegressor(
        n_estimators=100,
        max_depth=5,
        random_state=42
    ))
])

# 5. Division train/test
test_size = 0.2
random_seed = 42
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=test_size, random_state=random_seed
)

# ğŸ¯ Lancer une expÃ©rience MLflow
mlflow.set_experiment("student-score-regression-project")

with mlflow.start_run():
    print("ğŸš€ Nouvelle run MLflow dÃ©marrÃ©e")

    # ğŸ”§ Log des paramÃ¨tres
    mlflow.log_param("model_type", "RandomForestRegressor")
    mlflow.log_param("n_estimators", 100)
    mlflow.log_param("max_depth", 5)
    mlflow.log_param("test_size", test_size)
    mlflow.log_param("random_seed", random_seed)
    mlflow.log_param("n_features", X.shape[1])
    mlflow.log_param("categorical_cols", ", ".join(categorical_cols))

    # ğŸ‘¨â€ğŸ« EntraÃ®nement
    model.fit(X_train, y_train)

    # ğŸ” PrÃ©dictions
    y_pred = model.predict(X_test)

    # ğŸ“ˆ Ã‰valuation
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)
    rmse = mse ** 0.5
    r2 = r2_score(y_test, y_pred)

    # ğŸ“Š Log des mÃ©triques
    mlflow.log_metric("MAE", mae)
    mlflow.log_metric("MSE", mse)
    mlflow.log_metric("RMSE", rmse)
    mlflow.log_metric("R2", r2)
    mlflow.log_metric("train_samples", len(X_train))
    mlflow.log_metric("test_samples", len(X_test))

    # Create model signature and example
    signature = infer_signature(X_train, y_train)
    input_example = X_train.iloc[:5]  # Use first 5 rows as example

    # ğŸ’¾ Sauvegarde du modÃ¨le
    mlflow.sklearn.log_model(
        model, 
        name="student_model",  # Using name instead of artifact_path
        signature=signature,
        input_example=input_example
    )

    # âœ… RÃ©sumÃ©
    print(f"âœ… ModÃ¨le entraÃ®nÃ© avec R2: {r2:.2%}, RMSE: {rmse:.2f}")
    print("ğŸ“‹ ExpÃ©rience enregistrÃ©e dans MLflow !")
